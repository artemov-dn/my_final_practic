services:
  zookeeper-2:
    image: confluentinc/cp-zookeeper:7.4.4
    restart: always
    container_name: zookeeper-2
    hostname: zookeeper-2
    ports:
      - "2182:2182"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    networks:
      - kafka_net

  kafka-10:
    image: confluentinc/cp-kafka:7.4.4
    restart: always
    container_name: kafka-10
    hostname: kafka-10
    depends_on:
      - zookeeper-2
    ports:
      - "19094:19094"
      - "19991:19991"
    volumes:
      - data-kafka-10:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 10
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-2:2182
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_DELETE_TOPIC_ENABLE: true
      KAFKA_JMX_PORT: 19991
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:19094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-10:9092,CONTROLLER://kafka-10:9093,EXTERNAL://localhost:19094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
    networks:
      - kafka_net

  kafka-11:
    image: confluentinc/cp-kafka:7.4.4
    restart: always
    container_name: kafka-11
    hostname: kafka-11
    depends_on:
      - zookeeper-2
    ports:
      - "19095:19095"
      - "19992:19992"
    volumes:
      - data-kafka-11:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 11
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-2:2182
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_DELETE_TOPIC_ENABLE: true
      KAFKA_JMX_PORT: 19992      
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:19095
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-11:9092,CONTROLLER://kafka-11:9093,EXTERNAL://localhost:19095
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
    networks:
      - kafka_net
     
  kafka-12:
    image: confluentinc/cp-kafka:7.4.4
    restart: always
    container_name: kafka-12
    hostname: kafka-12
    depends_on:
      - zookeeper-2
    ports:
      - "19096:19096"
      - "19993:19993"
    volumes:
      - data-kafka-12:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 12
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-2:2182
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_DELETE_TOPIC_ENABLE: true
      KAFKA_JMX_PORT: 19993
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,EXTERNAL://0.0.0.0:19096
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-12:9092,CONTROLLER://kafka-12:9093,EXTERNAL://localhost:19096
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_MIN_INSYNC_REPLICAS: 2
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
    networks:
      - kafka_net
      
  ui-2:
    image: provectuslabs/kafka-ui:v0.7.0
    container_name: ui-2
    hostname: ui-2
    ports:
      - "8085:8080"
    environment:
      KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS: kafka-10:9092,kafka-11:9092,kafka-12:9092
      KAFKA_CLUSTERS_0_NAME: other_cluster
    networks:
      - kafka_net
      
      
  mirror-maker:
    image: confluentinc/cp-kafka:7.4.4
    volumes:
      - ./consumer.cfg:/etc/consumer.cfg
      - ./producer.cfg:/etc/producer.cfg
    command: bash -c "cub kafka-ready -z zookeeper-2:2182 1 30 && kafka-mirror-maker --consumer.config /etc/consumer.cfg --producer.config /etc/producer.cfg --whitelist 'client-requests,filtered-products' --num.streams 1"
    depends_on:
      - kafka-10
      - kafka-11
      - kafka-12
    networks:
      - kafka_net

  jmx-kafka-10:
    image: "sscaling/jmx-prometheus-exporter"
    restart: unless-stopped
    ports:
      - "15556:5556"
    environment:
      CONFIG_YML : "/etc/jmx_exporter/config.yml"
      JVM_OPTS: "-Xmx128M"
    volumes:
      - ./etc/jmx_exporter/config_kafka_10.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka-10
    depends_on:
      - kafka-10
    networks:
      - kafka_net
     
  jmx-kafka-11:
    image: "sscaling/jmx-prometheus-exporter"
    restart: unless-stopped
    ports:
      - "15557:5556"
    environment:
      CONFIG_YML : "/etc/jmx_exporter/config.yml"
      JVM_OPTS: "-Xmx128M"
    volumes:
      - ./etc/jmx_exporter/config_kafka_11.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka-11
    depends_on:
      - kafka-11
    networks:
      - kafka_net
     
  jmx-kafka-12:
    image: "sscaling/jmx-prometheus-exporter"
    restart: unless-stopped
    ports:
      - "15558:5556"
    environment:
      CONFIG_YML : "/etc/jmx_exporter/config.yml"
      JVM_OPTS: "-Xmx128M"
    volumes:
      - ./etc/jmx_exporter/config_kafka_12.yml:/etc/jmx_exporter/config.yml
    container_name: jmx-kafka-12
    depends_on:
      - kafka-12
    networks:
      - kafka_net

  prometheus-2:
    image: prom/prometheus:latest
    restart: unless-stopped   
    ports:
      - 9091:9090
    volumes:
      - ./etc/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./etc/prometheus/alert.rules:/etc/prometheus/alert.rules
    command: "--config.file=/etc/prometheus/prometheus.yml"
    container_name: prometheus-2
    networks:
      - kafka_net

  grafana-2:
    image: grafana/grafana:8.1.6
    restart: unless-stopped   
    ports:
      - "3002:3000"
    environment:
      GF_PATHS_DATA : /var/lib/grafana
      GF_SECURITY_ADMIN_PASSWORD : kafka
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    container_name: grafana-2
    depends_on:
      - prometheus-2
    networks:
      - kafka_net

  alertmanager-2:
    image: prom/alertmanager:v0.21.0
    restart: unless-stopped
    container_name: alertmanager-2
    volumes:
      - ./etc/alertmanager/config.yml:/etc/alertmanager/config.yml
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--log.level=debug'
    ports:
      - 9092:9093     
    networks:
      - kafka_net
      
      
  hadoop-namenode:
    image: apache/hadoop:3.4.0
    container_name: hadoop-namenode
    hostname: hadoop-namenode
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"
    shm_size: 10G
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./namenode_entrypoint.sh:/namenode_entrypoint.sh
    entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
    command: ["hdfs", "namenode"]
    networks:
      - kafka_net   
      
      
  hadoop-datanode-1:
    image: apache/hadoop:3.4.0
    container_name: hadoop-datanode-1
    hostname: hadoop-datanode-1
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9864:9864"
      - "9970:9970"
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - kafka_net   
      
      
  hadoop-datanode-2:
    image: apache/hadoop:3.4.0
    container_name: hadoop-datanode-2
    hostname: hadoop-datanode-2
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9865:9865"
      - "9971:9971"
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-2.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - kafka_net   
      
      
  hadoop-datanode-3:
    image: apache/hadoop:3.4.0
    container_name: hadoop-datanode-3
    hostname: hadoop-datanode-3
    user: "root"
    restart: always
    platform: linux/amd64
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: "2g"
    shm_size: 10G
    depends_on:
      - hadoop-namenode
    ports:
      - "9866:9866"
      - "9972:9972"
    volumes:
      - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/hdfs-site-datanode-3.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
    entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
    command: ["hdfs", "datanode"]
    networks:
      - kafka_net   
      
      
 # Apache Spark master node
  spark-master:
    image: bitnami/spark:3.5.4
    container_name: spark-master
    ports:
      - "8086:8080"  # HTTP-порт для Web UI Spark
      - "7077:7077"  # Порт для Spark master-сервис
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
    networks:
      - kafka_net   


 # Apache Spark worker node №1
  spark-worker-1:
    image: bitnami/spark:3.5.4
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - kafka_net   


 # Apache Spark worker node №2
  spark-worker-2:
    image: bitnami/spark:3.5.4
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    networks:
      - kafka_net   

      
volumes:
  data-kafka-10:
  data-kafka-11:
  data-kafka-12:

networks:
  kafka_net:      
    name: my_net